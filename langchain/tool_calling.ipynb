{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain_community.chat_models.azureml_endpoint import (\n",
    "    AzureMLChatOnlineEndpoint,\n",
    "    AzureMLEndpointApiType,\n",
    "    LlamaChatContentFormatter,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPEN_AI_API_KEY\")\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_SMALL_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./inputs/yelp.csv\")\n",
    "df_sample = df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     My wife took me here on my birthday for breakf...\n",
       "1     I have no idea why some people give bad review...\n",
       "2     love the gyro plate. Rice is so good and I als...\n",
       "3     Rosie, Dakota, and I LOVE Chaparral Dog Park!!...\n",
       "4     General Manager Scott Petello is a good egg!!!...\n",
       "                            ...                        \n",
       "95         Awesome subs clean and friendly well priced.\n",
       "96    Had dinner and brunch, not on the same day...t...\n",
       "97    This is a very interesting place.  Don't go he...\n",
       "98    I LOVE Chic Nails!\\r\\n\\r\\nI used to go to Tip ...\n",
       "99    After the Padres Spring Training game, we had ...\n",
       "Name: text, Length: 100, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Output Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "class ReviewInfo(BaseModel):\n",
    "    \"\"\"Information extracted from the text.\"\"\"\n",
    "    summary: str = Field(\n",
    "        description=\"A one-sentence summary of the review, maximum 50 words.\"\n",
    "    )\n",
    "    food: str = Field( \n",
    "        description=\"Classify the customer sentiment regarding the food of the restaurant in the review as positive, negative, or neutral. If there is no mention of food, return none.\",\n",
    "        enum=[\"positive\", \"negative\", \"neutral\", \"none\"]\n",
    "    )\n",
    "    service: str = Field( \n",
    "        description=\"Classify the customer sentiment regarding the service of the restaurant in the review as positive, negative, or neutral. If there is no mention of service, return none.\",\n",
    "        enum=[\"positive\", \"negative\", \"neutral\", \"none\"]\n",
    "    )\n",
    "    price: str = Field( \n",
    "        description=\"Classify the customer evaluation regarding the pricing of the restaurant in the review as positive, negative, or neutral. If there is no mention of pricing, return none.\",\n",
    "        enum=[\"positive\", \"negative\", \"neutral\", \"none\"]\n",
    "    )\n",
    "    ambience: str = Field(\n",
    "        description=\"Classify the customer sentiment regarding the ambience of the restaurant in the review as positive, negative, or neutral. If there is no mention of ambience, return none.\",\n",
    "        enum=[\"positive\", \"negative\", \"neutral\", \"none\"]\n",
    "    )\n",
    "    other: Optional[str] = Field(\n",
    "        description=\"Extract any other useful information from the review text to the business owner. If there is no other information, return an empty string.\"\n",
    "    )\n",
    "\n",
    "review_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm, specialized in restaurant review and customer sentiment analysis.\"\n",
    "            \"Only extract relevant information from the text as specified by the provided JSON schema. Do not generate any new information or exrta characters outside of the JSON schema.\"\n",
    "        ),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pydantic_parser = PydanticOutputParser(pydantic_object=ReviewInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `with_structured_output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['user_input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an expert extraction algorithm, specialized in restaurant review and customer sentiment analysis.Only extract relevant information from the text as specified by the provided JSON schema. Do not generate any new information or exrta characters outside of the JSON schema.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_input'], template='{user_input}'))])\n",
       "| RunnableBinding(bound=ChatMistralAI(client=<httpx.Client object at 0x000001C1592F9050>, async_client=<httpx.AsyncClient object at 0x000001C15853D3D0>, mistral_api_key=SecretStr('**********'), model='mistral-small-2402'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'ReviewInfo', 'description': 'Information extracted from the text.', 'parameters': {'type': 'object', 'properties': {'summary': {'description': 'A one-sentence summary of the review, maximum 50 words.', 'type': 'string'}, 'food': {'description': 'Classify the customer sentiment regarding the food of the restaurant in the review as positive, negative, or neutral. If there is no mention of food, return none.', 'enum': ['positive', 'negative', 'neutral', 'none'], 'type': 'string'}, 'service': {'description': 'Classify the customer sentiment regarding the service of the restaurant in the review as positive, negative, or neutral. If there is no mention of service, return none.', 'enum': ['positive', 'negative', 'neutral', 'none'], 'type': 'string'}, 'price': {'description': 'Classify the customer evaluation regarding the pricing of the restaurant in the review as positive, negative, or neutral. If there is no mention of pricing, return none.', 'enum': ['positive', 'negative', 'neutral', 'none'], 'type': 'string'}, 'ambience': {'description': 'Classify the customer sentiment regarding the ambience of the restaurant in the review as positive, negative, or neutral. If there is no mention of ambience, return none.', 'enum': ['positive', 'negative', 'neutral', 'none'], 'type': 'string'}, 'other': {'description': 'Extract any other useful information from the review text to the business owner. If there is no other information, return an empty string.', 'type': 'string'}}, 'required': ['summary', 'food', 'service', 'price', 'ambience']}}}], 'tool_choice': 'any'})\n",
       "| PydanticToolsParser(first_tool_only=True, tools=[<class '__main__.ReviewInfo'>])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test with Mistral small:\n",
    "llm = ChatMistralAI(model=\"mistral-small-2402\")\n",
    "chain = review_prompt | llm.with_structured_output(schema=ReviewInfo)\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'Customer was unhappy with the food, service, and pricing, and felt the salads were overpriced.',\n",
       " 'food': 'negative',\n",
       " 'service': 'negative',\n",
       " 'price': 'negative',\n",
       " 'ambience': 'none',\n",
       " 'other': 'The customer suggests teaching employees about upselling and informing customers about specials.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = df_sample['text'][15]\n",
    "review_structured = chain.invoke({\"user_input\": sample_text})\n",
    "review_structured.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using tool calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [ReviewInfo]\n",
    "llm = ChatMistralAI(model=\"mistral-small-2402\")\n",
    "llm_with_tools = llm.bind_tools(tools, tool_choice=\"any\") # use this to force the model to call at least one tool, supported by OpenAI, MistralAI, FireworksAI, and Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = review_prompt.format(user_input=sample_text)\n",
    "ai_message = llm_with_tools.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'C7Dp77JDH',\n",
       "  'function': {'name': 'ReviewInfo',\n",
       "   'arguments': '{\"summary\": \"The customer was disappointed with the service, pricing, and quality of food.\", \"food\": \"negative\", \"service\": \"negative\", \"price\": \"negative\", \"ambience\": \"none\", \"other\": \"The customer suggests the employees should upsell and inform about specials. Also, the customer finds the salads overpriced.\"}'}}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message.additional_kwargs['tool_calls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'csG0rYxTa',\n",
       "  'function': {'name': 'ReviewInfo',\n",
       "   'arguments': '{\"summary\": \"The customer was disappointed with their experience due to poor service and overpriced food, and felt they could have saved money with a special offer.\", \"food\": \"negative\", \"service\": \"negative\", \"price\": \"negative\", \"ambience\": \"none\", \"other\": \"The customer suggests the owner should train employees on upselling and informing customers about specials.\"}'}}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retry with another supported model\n",
    "llm = ChatMistralAI(model=\"open-mixtral-8x22b\")\n",
    "llm_with_tools = llm.bind_tools(tools, tool_choice=\"any\")\n",
    "query = review_prompt.format(user_input=sample_text)\n",
    "try:\n",
    "    ai_message = llm_with_tools.invoke(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "ai_message.additional_kwargs['tool_calls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error response 400 while fetching https://api.mistral.ai/v1/chat/completions: {\"object\":\"error\",\"message\":\"Function calling is not enabled for this model\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n",
      "Error response 400 while fetching https://api.mistral.ai/v1/chat/completions: {\"object\":\"error\",\"message\":\"Function calling is not enabled for this model\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n"
     ]
    }
   ],
   "source": [
    "# test with another model that does not support function calling:\n",
    "# using Mistral API, it will tell us that the model does not support function calling\n",
    "# this is a good way to test if the model supports function calling or not without second guessing\n",
    "\n",
    "llm = ChatMistralAI(model=\"open-mistral-7b\")\n",
    "chain = review_prompt | llm.with_structured_output(schema=ReviewInfo)\n",
    "sample_text = df_sample['text'][15]\n",
    "try:\n",
    "    review_structured = chain.invoke({\"user_input\": sample_text})\n",
    "    review_structured.dict()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools, tool_choice=\"any\")\n",
    "query = review_prompt.format(user_input=sample_text)\n",
    "try:\n",
    "    ai_message = llm_with_tools.invoke(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tools': [{'type': 'function',\n",
       "   'function': {'name': 'ReviewInfo',\n",
       "    'description': 'Information extracted from the text.',\n",
       "    'parameters': {'type': 'object',\n",
       "     'properties': {'summary': {'description': 'A one-sentence summary of the review, maximum 50 words.',\n",
       "       'type': 'string'},\n",
       "      'food': {'description': 'Classify the customer sentiment regarding the food of the restaurant in the review as positive, negative, or neutral. If there is no mention of food, return none.',\n",
       "       'enum': ['positive', 'negative', 'neutral', 'none'],\n",
       "       'type': 'string'},\n",
       "      'service': {'description': 'Classify the customer sentiment regarding the service of the restaurant in the review as positive, negative, or neutral. If there is no mention of service, return none.',\n",
       "       'enum': ['positive', 'negative', 'neutral', 'none'],\n",
       "       'type': 'string'},\n",
       "      'price': {'description': 'Classify the customer evaluation regarding the pricing of the restaurant in the review as positive, negative, or neutral. If there is no mention of pricing, return none.',\n",
       "       'enum': ['positive', 'negative', 'neutral', 'none'],\n",
       "       'type': 'string'},\n",
       "      'ambience': {'description': 'Classify the customer sentiment regarding the ambience of the restaurant in the review as positive, negative, or neutral. If there is no mention of ambience, return none.',\n",
       "       'enum': ['positive', 'negative', 'neutral', 'none'],\n",
       "       'type': 'string'},\n",
       "      'other': {'description': 'Extract any other useful information from the review text to the business owner. If there is no other information, return an empty string.',\n",
       "       'type': 'string'}},\n",
       "     'required': ['summary', 'food', 'service', 'price', 'ambience']}}}],\n",
       " 'tool_choice': 'any'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.with_structured_output(schema=ReviewInfo).first.kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-dos:\n",
    "# use \"mistral-7b\" on snowflake, it will return result as nothing is wrong\n",
    "# the 2 models on Azure under serverless API are Small and Large, which are commercial models and support functgion calling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-demo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
