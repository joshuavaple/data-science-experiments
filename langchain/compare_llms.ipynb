{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain_community.chat_models.azureml_endpoint import (\n",
    "    AzureMLChatOnlineEndpoint,\n",
    "    AzureMLEndpointApiType,\n",
    "    LlamaChatContentFormatter,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPEN_AI_API_KEY = os.getenv(\"OPEN_AI_API_KEY\")\n",
    "\n",
    "MISTRAL_SMALL_ENDPOINT = os.getenv(\"MISTRAL_SMALL_ENDPOINT\")\n",
    "MISTRAL_SMALL_API_KEY = os.getenv(\"MISTRAL_SMALL_API_KEY\")\n",
    "\n",
    "MISTRAL_LARGE_ENDPOINT = os.getenv(\"MISTRAL_LARGE_ENDPOINT\")\n",
    "MISTRAL_LARGE_API_KEY = os.getenv(\"MISTRAL_LARGE_API_KEY\")\n",
    "\n",
    "LLAMA3_8B_INSTRUCT_ENDPOINT = os.getenv(\"LLAMA3_8B_INSTRUCT_ENDPOINT\")\n",
    "LLAMA3_8B_INSTRUCT_API_KEY = os.getenv(\"LLAMA3_8B_INSTRUCT_API_KEY\")\n",
    "LLAMA3_8B_INSTRUCT_ENDPOINT_URL = LLAMA3_8B_INSTRUCT_ENDPOINT + \"/v1/chat/completions\"\n",
    "\n",
    "LLAMA3_70B_INSTRUCT_ENDPOINT = os.getenv(\"LLAMA3_70B_INSTRUCT_ENDPOINT\")\n",
    "LLAMA3_70B_INSTRUCT_API_KEY = os.getenv(\"LLAMA3_70B_INSTRUCT_API_KEY\")\n",
    "LLAMA3_70B_INSTRUCT_ENDPOINT_URL = LLAMA3_70B_INSTRUCT_ENDPOINT + \"/v1/chat/completions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./inputs/yelp.csv\")\n",
    "df_sample = df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     My wife took me here on my birthday for breakf...\n",
       "1     I have no idea why some people give bad review...\n",
       "2     love the gyro plate. Rice is so good and I als...\n",
       "3     Rosie, Dakota, and I LOVE Chaparral Dog Park!!...\n",
       "4     General Manager Scott Petello is a good egg!!!...\n",
       "                            ...                        \n",
       "95         Awesome subs clean and friendly well priced.\n",
       "96    Had dinner and brunch, not on the same day...t...\n",
       "97    This is a very interesting place.  Don't go he...\n",
       "98    I LOVE Chic Nails!\\n\\nI used to go to Tip & To...\n",
       "99    After the Padres Spring Training game, we had ...\n",
       "Name: text, Length: 100, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Output Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "class ReviewInfo(BaseModel):\n",
    "    \"\"\"Information extracted from the text.\"\"\"\n",
    "    summary: str = Field(\n",
    "        description=\"A one-sentence summary of the review, maximum 50 words.\"\n",
    "    )\n",
    "    food: str = Field( \n",
    "        description=\"Classify the customer sentiment regarding the food of the restaurant in the review as positive, negative, or neutral. If there is no mention of food, return none.\",\n",
    "        enum=[\"positive\", \"negative\", \"neutral\", \"none\"]\n",
    "    )\n",
    "    service: str = Field( \n",
    "        description=\"Classify the customer sentiment regarding the service of the restaurant in the review as positive, negative, or neutral. If there is no mention of service, return none.\",\n",
    "        enum=[\"positive\", \"negative\", \"neutral\", \"none\"]\n",
    "    )\n",
    "    price: str = Field( \n",
    "        description=\"Classify the customer evaluation regarding the pricing of the restaurant in the review as positive, negative, or neutral. If there is no mention of pricing, return none.\",\n",
    "        enum=[\"positive\", \"negative\", \"neutral\", \"none\"]\n",
    "    )\n",
    "    ambience: str = Field(\n",
    "        description=\"Classify the customer sentiment regarding the ambience of the restaurant in the review as positive, negative, or neutral. If there is no mention of ambience, return none.\",\n",
    "        enum=[\"positive\", \"negative\", \"neutral\", \"none\"]\n",
    "    )\n",
    "\n",
    "review_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm, specialized in restaurant review and customer sentiment analysis.\"\n",
    "            \"Only extract relevant information from the text as specified by the provided JSON schema. Do not generate any new information or exrta characters outside of the JSON schema.\"\n",
    "        ),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pydantic_parser = PydanticOutputParser(pydantic_object=ReviewInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with Mistral small:\n",
    "llm = ChatMistralAI(\n",
    "    endpoint=MISTRAL_SMALL_ENDPOINT,\n",
    "    mistral_api_key=MISTRAL_SMALL_API_KEY,\n",
    ")\n",
    "chain = review_prompt | llm.with_structured_output(schema=ReviewInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Was it worth the 21$ for a salad and small pizza? Absolutely not! Bad service. Maybe the guys grandma died I don\\'t know. I want to tell you what really made me mad about the experience. We order the small pizza and salad and the guys could have cared less and took our $ and we sat down. We were looking around and hmm, there\\'s a sign saying \"x large pizza and large salad only 23$\". Wow that would have been nice if the guy told us that. I left hungry, mad and unsatisfied. \\n\\nTo the owner: teach your employees the value of upselling and telling the specials. Something so small can affect a customers experience negatively. \\n\\nAnd your salads are severely overpriced \\n\\nWon\\'t go back unless I\\'m desperate.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['text'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'The restaurant served overpriced food with poor service and did not inform about better deals.',\n",
       " 'food': 'negative',\n",
       " 'service': 'negative',\n",
       " 'price': 'negative',\n",
       " 'ambience': 'none'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = df_sample['text'][15]\n",
    "review_structured = chain.invoke({\"user_input\": sample_text})\n",
    "review_structured.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReviewInfo(summary='The restaurant served overpriced food with poor service and did not inform about better deals.', food='negative', service='negative', price='negative', ambience='none')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the output with pydantic parser:\n",
    "# not necessary, as the output is already validated by the chain\n",
    "# we can add a try-except block to catch any errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-demo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
