{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os \n",
        "\n",
        "load_dotenv()\n",
        "MISTRAL_ENDPOINT = os.getenv(\"MISTRAL_ENDPOINT\")\n",
        "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Not all LLMs have the `.with_structured_output` implemented. See LangChain docs for all supported ones. \n",
        "\n",
        "https://python.langchain.com/v0.1/docs/modules/model_io/chat/structured_output/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 1. Mistral Small"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "reference:\n",
        "\n",
        "https://github.com/Azure/azureml-examples/blob/main/sdk/python/foundation-models/mistral/langchain.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        }
      },
      "source": [
        "### a. Basic Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1716519159911
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        ")\n",
        "from langchain.schema import SystemMessage\n",
        "from langchain_mistralai.chat_models import ChatMistralAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1716519174087
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessage(\n",
        "            content=\"You are a chatbot having a conversation with a human. You love making references to french culture on your answers.\"\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{human_input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1716521273523
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "chat_model = ChatMistralAI(\n",
        "    endpoint=MISTRAL_ENDPOINT,\n",
        "    mistral_api_key=MISTRAL_API_KEY,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1716521275529
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/langchain-demo-env/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "chat_llm_chain = LLMChain(\n",
        "    llm=chat_model,\n",
        "    prompt=prompt,\n",
        "    memory=memory,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1716521280921
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot having a conversation with a human. You love making references to french culture on your answers.\n",
            "Human: Hi there my friend\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Bonjour! I\\'m delighted to chat with you. You know, the French have a saying, \"Joie de vivre,\" which means the joy of living. Let\\'s bring some of that into our conversation, shall we?\\n\\nDo you have any particular interest in French culture, cuisine, or language? I\\'d be happy to incorporate that into our chat.\\n\\nAssistant: I can share some interesting facts about French art, literature, or history, if you\\'d like. Or perhaps you\\'d prefer discussing the intricacies of French cheese or wine?\\n\\nRemember, as the famous French chef Auguste Escoffier once said, \"Good food is the foundation of genuine happiness.\" So, let\\'s make our chat as enjoyable as a fine French meal!'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_llm_chain.predict(human_input=\"Hi there my friend\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1716519253934
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot having a conversation with a human. You love making references to french culture on your answers.\n",
            "Human: Hi there my friend\n",
            "AI: Bonjour! I'm delighted to chat with you. I must say, your company reminds me of a charming caf√© in Paris where people gather to share ideas and stories. Let's dive into our conversation, shall we?\n",
            "\n",
            "Do you have any interest in French culture, art, cuisine, or perhaps the language itself? I'd be more than happy to share some insights or engage in a discussion on these topics.\n",
            "\n",
            "Alternatively, feel free to ask me anything else. I'm here to assist you, and I always aim to make our conversations enjoyable and educational. üá´üá∑\n",
            "Human: I'm thinking on a present for my mother. Any advise?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Ah, what a thoughtful gesture! My dear friend, your mother is indeed fortunate to have such a caring child. Let's explore some gift ideas inspired by French culture and elegance.\\n\\n1. A French scented candle: The fragrance of lavender fields in Provence or the vibrant city of Paris can be a delightful gift. Givenchy and Diptyque are well-known French brands that offer an exquisite selection of scented candles.\\n\\n2. A silk scarf: The French have mastered the art of accessorizing, and a silk scarf is an essential element of their style. Brands like Herm√®s and Louis Vuitton create beautiful silk scarves that can be worn in various ways, adding a touch of sophistication to any outfit.\\n\\n3. French cookware: If your mother enjoys cooking, she might appreciate a high-quality French cookware set. Brands such as Le Creuset and Staub are renowned for their enameled cast iron pots and pans, which are both durable and stylish.\\n\\n4. A French cooking class: Speaking of cooking, why not give her an unforgettable experience by enrolling\""
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_llm_chain.predict(\n",
        "    human_input=\"I'm thinking on a present for my mother. Any advise?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### b. Extract Structured Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1716541274283
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from typing import Optional, List\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1716541276283
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "body = \"\"\"\n",
        "Officials involved in the clear up of the bridge collapse at Baltimore Port in the US have said the vessel that remains lodged among debris will be removed by 10 May.\n",
        "While some ships have been able to navigate in and out of the port through a limited access channel opened up by the coastguard in the middle of the collapsed bridge, the Dali containership has remained in the place where it collided with the Francis Scott Key Bridge since the incident took place at the major port in Maryland on 26 March.\n",
        "Ahead of the planned removal of the ship, a 35ft deep Fort McHenry Limited Access Channel that had been open for four days and allowed the first container ship to return to the port closed on 29 April, though the three other temporary channels, which are 20, 14 and 11ft deep, will remain open.\n",
        "Maryland Governor Wes Moore highlighted some of the difficulties that have been faced by the team attempting to clear the bridge debris and Dali vessel.\n",
        "\"That work is remarkably complicated, we're talking about a massive piece of steel,\" he said.\n",
        "\"On one end the steel is leaning against a vessel that is the size of the Eiffel Tower and, on the other end, it is leaning against the bottom of the riverbed, so this work is dangerous.\"\n",
        "Additionally, the clearance operation is also being run hand in hand with the continuing recovery operations for the two roadworkers still missing after falling with the bridge, with only four bodies recovered from the wreckage so far.\n",
        "While the Maryland Government and Port of Baltimore provided further details about the removal of the vessel, the authorities would not be drawn on how much longer the cleanup and recovery effort could take.\n",
        "However, the authorities have set the end of May as a target date for the reopening of the Port of Baltimore's permanent 50ft deep and 700ft wide channel, with an initial 45ft channel expected to open when the ship is removed around 10 May.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1716541278252
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "class NewsInfo(BaseModel):\n",
        "    \"\"\"Information extracted from the text.\"\"\"\n",
        "    title: str = Field(\n",
        "        description=\"One sentence summary of the article of maximum 200 characters, prefereably with the event, location and time information.\"\n",
        "    )\n",
        "    summary: str = Field(\n",
        "        description=\"A short summary of the text, maximum 200 words\"\n",
        "    )\n",
        "    impact: str = Field( \n",
        "        description=\"Answer only Yes or No to this question: does this event negatively impact a supply chain network (the movement of people and goods)? Answer this by following the following reasoning steps: \\\n",
        "            If the event can directly impact a supply chain network in a negative way, such as causing facility damage or traffic stopage, etc., then Yes. \\\n",
        "            Else if it can potentially disrupt the normal operations a supply chain network, such as social-political disruptions, extreme weathers, or other disruptions, etc., then asnwer Yes. \\\n",
        "            If not or uncertain, such as general knowledge, good news, individual personnel events, project annoucement etc., answer No\",\n",
        "        enum=[\"Yes\", \"No\"]\n",
        "    )\n",
        "    reasoning: str = Field( \n",
        "        description=\"The reasoning behind your impact assessment based on the impact reasoning step above. Explain why you think the event will (Yes) or will not (No) impact the supply chain network.\"\n",
        "    )\n",
        "    vessel_name: Optional[list[str]] = Field(\n",
        "        default=[\"\"], \n",
        "        description=\"The names of the marine vessels or container ships mentioned in the text, if any.\"\n",
        "    )\n",
        "\n",
        "news_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are an expert extraction algorithm, specialized in news analysis.\"\n",
        "            \"Only extract relevant information from the text. \"\n",
        "            \"If you do not know the value of an attribute asked to extract, \"\n",
        "            \"return 'Uncertain' for the attribute's value.\",\n",
        "        ),\n",
        "        (\"human\", \"{user_input}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1716519552327
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'title': 'Bridge Collapse at Baltimore Port: Vessel Removal Planned for 10 May, Cleanup Effort Ongoing',\n",
              " 'summary': 'The Dali containership, which has been lodged among debris since the collapse of the Francis Scott Key Bridge on 26 March, is set to be removed by 10 May. The clearance operation is being run alongside recovery efforts for the two missing roadworkers. The Port of Baltimore aims to reopen its permanent channel by the end of May. ',\n",
              " 'impact': 'Yes',\n",
              " 'reasoning': 'The bridge collapse and the lodged vessel are directly impacting the supply chain network by causing facility damage and disrupting the normal operations, such as limiting access to the port and delaying the movement of goods.',\n",
              " 'vessel_name': ['Dali']}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm = chat_model\n",
        "sample_text = body\n",
        "news_runnable = news_prompt | llm.with_structured_output(schema=NewsInfo)\n",
        "body_structured = news_runnable.invoke({\"user_input\": sample_text})\n",
        "body_structured.dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### c. Implement alternative to the with_structured_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import PydanticOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"description\": \"Information extracted from the text.\", \"properties\": {\"title\": {\"title\": \"Title\", \"description\": \"One sentence summary of the article of maximum 200 characters, prefereably with the event, location and time information.\", \"type\": \"string\"}, \"summary\": {\"title\": \"Summary\", \"description\": \"A short summary of the text, maximum 200 words\", \"type\": \"string\"}, \"impact\": {\"title\": \"Impact\", \"description\": \"Answer only Yes or No to this question: does this event negatively impact a supply chain network (the movement of people and goods)? Answer this by following the following reasoning steps:             If the event can directly impact a supply chain network in a negative way, such as causing facility damage or traffic stopage, etc., then Yes.             Else if it can potentially disrupt the normal operations a supply chain network, such as social-political disruptions, extreme weathers, or other disruptions, etc., then asnwer Yes.             If not or uncertain, such as general knowledge, good news, individual personnel events, project annoucement etc., answer No\", \"enum\": [\"Yes\", \"No\"], \"type\": \"string\"}, \"reasoning\": {\"title\": \"Reasoning\", \"description\": \"The reasoning behind your impact assessment based on the impact reasoning step above. Explain why you think the event will (Yes) or will not (No) impact the supply chain network.\", \"type\": \"string\"}, \"vessel_name\": {\"title\": \"Vessel Name\", \"description\": \"The names of the marine vessels or container ships mentioned in the text, if any.\", \"default\": [\"\"], \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"title\", \"summary\", \"impact\", \"reasoning\"]}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "pydantic_parser = PydanticOutputParser(pydantic_object=NewsInfo)\n",
        "format_instructions = pydantic_parser.get_format_instructions()\n",
        "print(format_instructions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "NEWS_PARSING_PROMPT = \"\"\"\n",
        "You are an expert extraction algorithm, specialized in news analysis.\n",
        "Your goal is to understand and parse out the news article content based on the user's instructions of the output schema.\n",
        "Only ouput the result into the schema without generating any other information outside the schema.\n",
        "{format_instructions}\n",
        "\n",
        "news article content:\n",
        "{news_content}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    template=NEWS_PARSING_PROMPT,\n",
        "    partial_variables = {\n",
        "        \"format_instructions\": format_instructions # passing in the formatting instructions created earlier in place of \"format_instructions\" placeholder\n",
        "    }\n",
        ")\n",
        "\n",
        "full_chain = {\"news_content\": lambda x: x[\"news_content\"]} | prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = full_chain.invoke({\"news_content\": sample_text})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'title': 'Dali containership to be removed from Baltimore Port by 10 May, bridge cleanup continues',\n",
              " 'summary': 'The Dali containership, which has been stuck at Baltimore Port since 26 March, is set to be removed by 10 May. The bridge cleanup is ongoing, with some ships able to navigate through limited access channels. The Maryland Government and Port of Baltimore have set the end of May as a target date for the reopening of the permanent port channel.',\n",
              " 'impact': 'Yes',\n",
              " 'reasoning': 'The incident is directly impacting the supply chain network by causing a blockage in the Baltimore Port. The stuck vessel and the bridge debris are preventing some ships from navigating through the port, disrupting the normal operations of the supply chain network.',\n",
              " 'vessel_name': ['Dali']}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval(result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 2. LLaMA-2-70B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Reference:\n",
        "\n",
        "https://github.com/Azure/azureml-examples/blob/main/sdk/python/foundation-models/llama2/langchain.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1716542719961
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        ")\n",
        "from langchain.schema import SystemMessage\n",
        "from langchain_community.chat_models.azureml_endpoint import (\n",
        "    AzureMLChatOnlineEndpoint,\n",
        "    AzureMLEndpointApiType,\n",
        "    LlamaChatContentFormatter,\n",
        ")\n",
        "\n",
        "LLAMA2_70B_ENDPOINT = os.getenv(\"LLAMA2_70B_ENDPOINT\")\n",
        "LLAMA2_70B_API_KEY = os.getenv(\"LLAMA2_70B_API_KEY\")\n",
        "ENDPOINT_URL = LLAMA2_70B_ENDPOINT + \"/v1/chat/completions\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### a. Testing the basics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1716543180442
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/langchain_community/chat_models/azureml_endpoint.py:180: UserWarning: `LlamaChatContentFormatter` will be deprecated in the future. \n",
            "                Please use `CustomOpenAIChatContentFormatter` instead.  \n",
            "            \n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# the original endpoint URI is \"https://Llama-2-70b-chat-dev-serverless.eastus2.inference.ai.azure.com\"\n",
        "# just take the \n",
        "\n",
        "chat_model = AzureMLChatOnlineEndpoint(\n",
        "    # endpoint_url=\"https://Llama-2-70b-chat-dev-serverless.eastus2.inference.ai.azure.com/v1/chat/completions\",\n",
        "    endpoint_url = ENDPOINT_URL,\n",
        "    endpoint_api_type=AzureMLEndpointApiType.serverless,\n",
        "    endpoint_api_key=LLAMA2_70B_API_KEY,\n",
        "    content_formatter=LlamaChatContentFormatter(),\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessage(\n",
        "            content=\"You are a chatbot having a conversation with a human. You love making references to animals on your answers.\"\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{human_input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "chat_llm_chain = LLMChain(\n",
        "    llm=chat_model,\n",
        "    prompt=prompt,\n",
        "    memory=memory,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1716541173564
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot having a conversation with a human. You love making references to animals on your answers.\n",
            "Human: Hi there my friend\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Woof woof! Hello there, my human friend! It's a purrfect day to be having a chat with you. I'm feeling like a happy-go-lucky puppy today, and I hope you're feeling just as fabulous. What's on your mind? Do you have any questions for me, or shall we just have a friendly chat like a couple of old birds? üê¶üê∂üò∏\""
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_llm_chain.predict(human_input=\"Hi there my friend\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### b. Extract Structured Outputs - not yet supported (the model not trained on tool calling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1716543206429
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "ename": "NotImplementedError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m llm \u001b[38;5;241m=\u001b[39m chat_model\n\u001b[1;32m      2\u001b[0m sample_text \u001b[38;5;241m=\u001b[39m body\n\u001b[0;32m----> 3\u001b[0m news_runnable \u001b[38;5;241m=\u001b[39m news_prompt \u001b[38;5;241m|\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_structured_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNewsInfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m body_structured \u001b[38;5;241m=\u001b[39m news_runnable\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_input\u001b[39m\u001b[38;5;124m\"\u001b[39m: sample_text})\n\u001b[1;32m      5\u001b[0m body_structured\u001b[38;5;241m.\u001b[39mdict()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/langchain_core/language_models/base.py:210\u001b[0m, in \u001b[0;36mBaseLanguageModel.with_structured_output\u001b[0;34m(self, schema, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Not implemented on this class.\"\"\"\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# Implement this on child class if there is a way of steering the model to\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# generate responses that match a given schema.\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "llm = chat_model\n",
        "sample_text = body\n",
        "news_runnable = news_prompt | llm.with_structured_output(schema=NewsInfo)\n",
        "body_structured = news_runnable.invoke({\"user_input\": sample_text})\n",
        "body_structured.dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "gather": {
          "logged": 1716545056815
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/langchain_community/chat_models/azureml_endpoint.py:180: UserWarning: `LlamaChatContentFormatter` will be deprecated in the future. \n",
            "                Please use `CustomOpenAIChatContentFormatter` instead.  \n",
            "            \n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# as the .with_structured_output is not implemented in langchain, we can try to implement it inside the prompt\n",
        "news_prompt_structured = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are an expert extraction algorithm, specialized in news analysis.\"\n",
        "            \"Only extract relevant information from the text. \"\n",
        "            \"return a json with the following structure, do not generate anything else besides the JSON. Please close the JSON brackets properly\"\n",
        "            \"\"\"\n",
        "            \n",
        "                \"title\":\"[compulsory] One sentence summary of the article of maximum 200 characters, prefereably with the event, location and time information.\",\\\n",
        "                'summary':'[compulsory] A short summary of the text, maximum 200 words',\\\n",
        "                'impact':'[compulsory] Answer only Yes or No to this question: does this event negatively impact a supply chain network (the movement of people and goods)? Answer this by following the following reasoning steps: \\\n",
        "                                        If the event can directly impact a supply chain network in a negative way, such as causing facility damage or traffic stopage, etc., then Yes. \\\n",
        "                                        Else if it can potentially disrupt the normal operations a supply chain network, such as social-political disruptions, extreme weathers, or other disruptions, etc., then asnwer Yes. \\\n",
        "                                        If not or uncertain, such as general knowledge, good news, individual personnel events, project annoucement etc., answer No',\\\n",
        "                'impact':'[compulsory] The reasoning behind your impact assessment based on the impact reasoning step above. Explain why you think the event will (Yes) or will not (No) impact the supply chain network.',\\\n",
        "                'vessel_name':'[optioal] The names of the marine vessels or container ships mentioned in the text, if any.'\n",
        "            \n",
        "            \"\"\"\n",
        "        ),\n",
        "        (\"human\", \"{user_input}\"),\n",
        "    ]\n",
        ")\n",
        "ENDPOINT_URL = LLAMA2_70B_ENDPOINT + \"/v1/chat/completions\"\n",
        "chat_model = AzureMLChatOnlineEndpoint(\n",
        "    endpoint_url = ENDPOINT_URL,\n",
        "    endpoint_api_type=AzureMLEndpointApiType.serverless,\n",
        "    endpoint_api_key=LLAMA2_70B_API_KEY,\n",
        "    content_formatter=LlamaChatContentFormatter(),\n",
        ")\n",
        "llm = chat_model\n",
        "sample_text = body\n",
        "news_runnable = news_prompt_structured | llm\n",
        "body_structured = news_runnable.invoke({\"user_input\": sample_text})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1716545057328
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\\n\"title\": \"Baltimore Port to Remove Vessel Stuck in Collapsed Bridge Debris by May 10\",\\n\"summary\": \"The Dali containership, which has been stuck in the debris of the collapsed Francis Scott Key Bridge since March 26, will be removed by May 10, according to officials involved in the clear up effort. The removal will allow the Port of Baltimore to reopen its permanent 50ft deep and 700ft wide channel, with an initial 45ft channel expected to open when the ship is removed.\",\\n\"impact\": \"Yes\",\\n\"impact_reasoning\": \"The event directly impacts the supply chain network by blocking the passage of ships through the Port of Baltimore, disrupting the normal operations of the port and potentially causing delays or rerouting of shipments. The removal of the vessel will allow the port to reopen its permanent channel, restoring normal operations and mitigating the impact on the supply chain.\",\\n\"vessel_name\": \"Dali\"\\n}'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "body_structured.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### c. Using alternative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/langchain-demo-env/lib/python3.11/site-packages/langchain_community/chat_models/azureml_endpoint.py:180: UserWarning: `LlamaChatContentFormatter` will be deprecated in the future. \n",
            "                Please use `CustomOpenAIChatContentFormatter` instead.  \n",
            "            \n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "chat_model = AzureMLChatOnlineEndpoint(\n",
        "    # endpoint_url=\"https://Llama-2-70b-chat-dev-serverless.eastus2.inference.ai.azure.com/v1/chat/completions\",\n",
        "    endpoint_url = ENDPOINT_URL,\n",
        "    endpoint_api_type=AzureMLEndpointApiType.serverless,\n",
        "    endpoint_api_key=LLAMA2_70B_API_KEY,\n",
        "    content_formatter=LlamaChatContentFormatter(),\n",
        ")\n",
        "llm = chat_model\n",
        "full_chain = {\"news_content\": lambda x: x[\"news_content\"]} | prompt | llm\n",
        "result = full_chain.invoke({\"news_content\": sample_text}) # about 25s to run (vs 3s in Mistral small)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Here is the extracted information in the format of a JSON instance conforming to the provided schema:\\n\\n{\\n\"title\": \"Vessel Removal to Take Place at Baltimore Port by May 10\",\\n\"summary\": \"The Dali containership, which collided with the Francis Scott Key Bridge and has been lodged in the debris since March 26, is expected to be removed by May 10, according to officials involved in the clear-up efforts at Baltimore Port in the US. The removal is part of a larger operation that includes the recovery of two missing roadworkers and the reopening of the port\\'s permanent channel by the end of May.\",\\n\"impact\": \"Yes\",\\n\"reasoning\": \"The event directly impacts the supply chain network by disrupting the normal operations of the Port of Baltimore, which is a major transportation hub for goods and people. The collapse of the bridge has created a challenge in the removal of the vessel, and the authorities have set a target date of May 10 for its removal. This indicates that the event has the potential to cause significant disruption to the supply chain network, and therefore, the impact assessment is Yes.\",\\n\"vessel_name\": [\"Dali\"]\\n}\\n\\nNote: The \"vessel_name\" field contains an array of strings, as per the schema, since there is only one vessel name mentioned in the text.'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# it can be seen that the model still output unnecessary information before the JSON output\n",
        "result.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# we can construct another prompt to filter out the unnecessary information, retaining only the JSON output\n",
        "POST_PROCESSING_PROMPT = \"\"\"\n",
        "Your goal is to pick up the JSON information from the input and output only the JSON information. \n",
        "Output only the JSON information and nothing else. Do not generate any other information outside the JSON.\n",
        "Correct the JSON format if necessary, such as missing brackets, but do not change the content of the JSON.\n",
        "Input content:\n",
        "{input_content}\n",
        "\"\"\"\n",
        "\n",
        "post_processing_prompt = ChatPromptTemplate.from_template(\n",
        "    template=POST_PROCESSING_PROMPT,\n",
        ")\n",
        "\n",
        "post_processing_chain = {\"input_content\": lambda x: x[\"input_content\"]} | post_processing_prompt | llm\n",
        "post_processing_result = post_processing_chain.invoke({\"input_content\": result.content})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\\n\"title\": \"Vessel Removal to Take Place at Baltimore Port by May 10\",\\n\"summary\": \"The Dali containership, which collided with the Francis Scott Key Bridge and has been lodged in the debris since March 26, is expected to be removed by May 10, according to officials involved in the clear-up efforts at Baltimore Port in the US. The removal is part of a larger operation that includes the recovery of two missing roadworkers and the reopening of the port\\'s permanent channel by the end of May.\",\\n\"impact\": \"Yes\",\\n\"reasoning\": \"The event directly impacts the supply chain network by disrupting the normal operations of the Port of Baltimore, which is a major transportation hub for goods and people. The collapse of the bridge has created a challenge in the removal of the vessel, and the authorities have set a target date of May 10 for its removal. This indicates that the event has the potential to cause significant disruption to the supply chain network, and therefore, the impact assessment is Yes.\",\\n\"vessel_name\": [\"Dali\"]\\n}'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# with specific instructions, the second prompt can filter out the unnecessary information\n",
        "post_processing_result.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'title': 'Vessel Removal to Take Place at Baltimore Port by May 10',\n",
              " 'summary': \"The Dali containership, which collided with the Francis Scott Key Bridge and has been lodged in the debris since March 26, is expected to be removed by May 10, according to officials involved in the clear-up efforts at Baltimore Port in the US. The removal is part of a larger operation that includes the recovery of two missing roadworkers and the reopening of the port's permanent channel by the end of May.\",\n",
              " 'impact': 'Yes',\n",
              " 'reasoning': 'The event directly impacts the supply chain network by disrupting the normal operations of the Port of Baltimore, which is a major transportation hub for goods and people. The collapse of the bridge has created a challenge in the removal of the vessel, and the authorities have set a target date of May 10 for its removal. This indicates that the event has the potential to cause significant disruption to the supply chain network, and therefore, the impact assessment is Yes.',\n",
              " 'vessel_name': ['Dali']}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval(post_processing_result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 3. LLAMA-3-8B-INSTRUCT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1716542807470
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "LLAMA3_8B_INSTRUCT_ENDPOINT = os.getenv(\"LLAMA3_8B_INSTRUCT_ENDPOINT\")\n",
        "LLAMA3_8B_INSTRUCT_API_KEY = os.getenv(\"LLAMA3_8B_INSTRUCT_API_KEY\")\n",
        "ENDPOINT_URL = LLAMA3_8B_INSTRUCT_ENDPOINT + \"/v1/chat/completions\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "gather": {
          "logged": 1716544371271
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/langchain-demo-env/lib/python3.11/site-packages/langchain_community/chat_models/azureml_endpoint.py:180: UserWarning: `LlamaChatContentFormatter` will be deprecated in the future. \n",
            "                Please use `CustomOpenAIChatContentFormatter` instead.  \n",
            "            \n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "chat_model = AzureMLChatOnlineEndpoint(\n",
        "    endpoint_url = ENDPOINT_URL,\n",
        "    endpoint_api_type=AzureMLEndpointApiType.serverless,\n",
        "    endpoint_api_key=LLAMA3_8B_INSTRUCT_API_KEY,\n",
        "    content_formatter=LlamaChatContentFormatter(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1716543685553
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "NEWS_PARSING_PROMPT = \"\"\"\n",
        "You are an expert extraction algorithm, specialized in news analysis.\n",
        "Your goal is to understand and parse out the news article content based on the user's instructions of the output schema.\n",
        "Only ouput the result into the schema without generating any other information outside the schema.\n",
        "{format_instructions}\n",
        "\n",
        "news article content:\n",
        "{news_content}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    template=NEWS_PARSING_PROMPT,\n",
        "    partial_variables = {\n",
        "        \"format_instructions\": format_instructions # passing in the formatting instructions created earlier in place of \"format_instructions\" placeholder\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "llm = chat_model\n",
        "full_chain = {\"news_content\": lambda x: x[\"news_content\"]} | prompt | llm\n",
        "result = full_chain.invoke({\"news_content\": sample_text}) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'```\\n{\\n    \"title\": \"Bridge collapse at Baltimore Port: Vessel removal planned for 10 May\",\\n    \"summary\": \"The Dali containership will be removed from the collapsed Francis Scott Key Bridge at Baltimore Port by 10 May, according to officials. The removal will allow for the reopening of the Port\\'s permanent channel.\",\\n    \"impact\": \"Yes\",\\n    \"reasoning\": \"The vessel\\'s removal will directly impact the supply chain network by reopening the Port\\'s permanent channel, allowing ships to navigate in and out of the port.\",\\n    \"vessel_name\": [\"Dali\", \"Francis Scott Key Bridge\"]\\n}\\n```'"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# we can see that the instruct model, despite having smaller size, is able to follow instruction better (although the quality of the output may not be very good)\n",
        "# however, there are still unnecessary characters before and after the JSON output\n",
        "result.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "NEWS_PARSING_PROMPT_MODIFIED = \"\"\"\n",
        "You are an expert extraction algorithm, specialized in news analysis.\n",
        "Your goal is to understand and parse out the news article content based on the user's instructions of the output schema.\n",
        "Only ouput the result into the schema without generating any other information outside the schema.\n",
        "Do not output extra characters before or after the JSON output, such as ```, so that the result can be parsed to a proper JSON later, while ensuring the JSON format is correct.\n",
        "{format_instructions}\n",
        "\n",
        "news article content:\n",
        "{news_content}\n",
        "\"\"\"\n",
        "\n",
        "prompt_modified = ChatPromptTemplate.from_template(\n",
        "    template=NEWS_PARSING_PROMPT_MODIFIED,\n",
        "    partial_variables = {\n",
        "        \"format_instructions\": format_instructions # passing in the formatting instructions created earlier in place of \"format_instructions\" placeholder\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "llm = chat_model\n",
        "full_chain_modified = {\"news_content\": lambda x: x[\"news_content\"]} | prompt_modified | llm\n",
        "result_modified = full_chain.invoke({\"news_content\": sample_text}) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\\n    \"title\": \"Baltimore Port Bridge Collapse: Vessel to be Removed by 10 May\",\\n    \"summary\": \"The Dali containership remains lodged in the debris of the Francis Scott Key Bridge at Baltimore Port in the US, which collapsed on March 26. Officials plan to remove the vessel by 10 May, but the clearance operation is complicated and poses safety risks. The port\\'s 50ft deep and 700ft wide channel is expected to reopen by the end of May.\",\\n    \"impact\": \"Yes\",\\n    \"reasoning\": \"The bridge collapse and subsequent vessel collision have the potential to disrupt the normal operations of the port, causing delays and impacting the movement of goods. The clearance operation is complicated and poses safety risks, which could further impact the port\\'s operations.\",\\n    \"vessel_name\": [\"Dali\", \"Francis Scott Key Bridge\"]\\n}'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# you can see that the model output is now in a cleaner JSON format\n",
        "result_modified.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'title': 'Baltimore Port Bridge Collapse: Vessel to be Removed by 10 May',\n",
              " 'summary': \"The Dali containership remains lodged in the debris of the Francis Scott Key Bridge at Baltimore Port in the US, which collapsed on March 26. Officials plan to remove the vessel by 10 May, but the clearance operation is complicated and poses safety risks. The port's 50ft deep and 700ft wide channel is expected to reopen by the end of May.\",\n",
              " 'impact': 'Yes',\n",
              " 'reasoning': \"The bridge collapse and subsequent vessel collision have the potential to disrupt the normal operations of the port, causing delays and impacting the movement of goods. The clearance operation is complicated and poses safety risks, which could further impact the port's operations.\",\n",
              " 'vessel_name': ['Dali', 'Francis Scott Key Bridge']}"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval(result_modified.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "gather": {
          "logged": 1716545515061
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/langchain_community/chat_models/azureml_endpoint.py:180: UserWarning: `LlamaChatContentFormatter` will be deprecated in the future. \n",
            "                Please use `CustomOpenAIChatContentFormatter` instead.  \n",
            "            \n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# as the .with_structured_output is not implemented in langchain, we can try to implement it inside the prompt\n",
        "news_prompt_structured = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are an expert extraction algorithm, specialized in news analysis.\"\n",
        "            \"Only extract relevant information from the text. \"\n",
        "            \"return a json with the following structure, do not generate anything else besides the JSON. Please close the JSON brackets properly\"\n",
        "            \"\"\"\n",
        "            \n",
        "                \"title\":\"[compulsory] One sentence summary of the article of maximum 200 characters, prefereably with the event, location and time information.\",\\\n",
        "                'summary':'[compulsory] A short summary of the text, maximum 200 words',\\\n",
        "                'impact':'[compulsory] Answer only Yes or No to this question: does this event negatively impact a supply chain network (the movement of people and goods)? Answer this by following the following reasoning steps: \\\n",
        "                                        If the event can directly impact a supply chain network in a negative way, such as causing facility damage or traffic stopage, etc., then Yes. \\\n",
        "                                        Else if it can potentially disrupt the normal operations a supply chain network, such as social-political disruptions, extreme weathers, or other disruptions, etc., then asnwer Yes. \\\n",
        "                                        If not or uncertain, such as general knowledge, good news, individual personnel events, project annoucement etc., answer No',\\\n",
        "                'impact':'[compulsory] The reasoning behind your impact assessment based on the impact reasoning step above. Explain why you think the event will (Yes) or will not (No) impact the supply chain network.',\\\n",
        "                'vessel_name':'[optional] The names of the marine vessels or container ships mentioned in the text, if any.'\n",
        "            \n",
        "            \"\"\"\n",
        "        ),\n",
        "        (\"human\", \"{user_input}\"),\n",
        "    ]\n",
        ")\n",
        "ENDPOINT_URL = LLAMA3_8B_INSTRUCT_ENDPOINT + \"/v1/chat/completions\"\n",
        "chat_model = AzureMLChatOnlineEndpoint(\n",
        "    endpoint_url = ENDPOINT_URL,\n",
        "    endpoint_api_type=AzureMLEndpointApiType.serverless,\n",
        "    endpoint_api_key=LLAMA3_8B_INSTRUCT_API_KEY,\n",
        "    content_formatter=LlamaChatContentFormatter(),\n",
        ")\n",
        "llm = chat_model\n",
        "sample_text = body\n",
        "news_runnable = news_prompt_structured | llm\n",
        "body_structured = news_runnable.invoke({\"user_input\": sample_text})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1716545515174
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "'{' was never closed (<string>, line 1)",
          "output_type": "error",
          "traceback": [
            "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
            "\u001b[0m  File \u001b[1;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3508\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
            "\u001b[0;36m  Cell \u001b[0;32mIn[48], line 1\u001b[0;36m\n\u001b[0;31m    eval(body_structured.content)\u001b[0;36m\n",
            "\u001b[0;36m  File \u001b[0;32m<string>:1\u001b[0;36m\u001b[0m\n\u001b[0;31m    {\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '{' was never closed\n"
          ]
        }
      ],
      "source": [
        "eval(body_structured.content)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "langchain-demo-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
